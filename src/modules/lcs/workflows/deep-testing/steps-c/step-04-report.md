---
name: 'step-04-report'
description: 'Finalize the deep-testing report with executive summary, global metrics, confidence assessment, and mark LCS pipeline Phase 0-4 as complete'

sidecarStatePath: '{output_folder}/lcs/sidecar-state.yaml'
deepTestingReportPath: '{output_folder}/lcs/deep-testing-report.md'
riskMapPath: '{output_folder}/lcs/risk-map.md'
safetyNetsReportPath: '{output_folder}/lcs/safety-nets-report.md'
refactoringReportPath: '{output_folder}/lcs/refactoring-report.md'
---

# Step 4: Final Report

## STEP GOAL:

To finalize the deep-testing report by synthesizing all zone outcomes into an executive summary, computing global metrics, assessing overall confidence, producing recommendations, and marking the deep-testing phase (and the LCS pipeline Phases 0-4) as complete.

## MANDATORY EXECUTION RULES (READ FIRST):

### Universal Rules:

- ğŸ“– CRITICAL: Read the complete step file before taking any action
- âš™ï¸ TOOL/SUBPROCESS FALLBACK: If any instruction references a subprocess, subagent, or tool you do not have access to, you MUST still achieve the outcome in your main context thread
- âœ… YOU MUST ALWAYS SPEAK OUTPUT in your Agent communication style with the config `{communication_language}`

### Role Reinforcement:

- âœ… You are Conrad, the LCS Lead â€” delivering the final assessment
- âœ… Be factual, concise, and actionable â€” the developer needs a clear picture of test coverage
- âœ… Highlight wins AND remaining gaps honestly
- âœ… This is the culmination of the entire LCS pipeline â€” present it with appropriate gravity

### Step-Specific Rules:

- ğŸ¯ Focus ONLY on report finalization and workflow completion
- ğŸš« FORBIDDEN to write tests, spawn teammates, or modify code
- ğŸ’¬ Present the report summary to the user before finalizing
- ğŸ“‹ This is the FINAL step â€” mark workflow AND LCS pipeline as complete

## EXECUTION PROTOCOLS:

- ğŸ¯ Follow the MANDATORY SEQUENCE exactly
- ğŸ’¾ Finalize `{deepTestingReportPath}` with all sections
- ğŸ’¾ Update `{sidecarStatePath}` with workflow and pipeline completion
- ğŸ“– This is the final step â€” no next step to load

## CONTEXT BOUNDARIES:

- Available: step-02 completed (all zones processed), step-03 completed (discoveries integrated)
- Focus: synthesis, metrics, recommendations only
- Limits: do not modify code, do not run tests, do not spawn teammates
- Dependencies: all zones processed AND discovery integration done

## MANDATORY SEQUENCE

**CRITICAL:** Follow this sequence exactly. Do not skip, reorder, or improvise unless user explicitly requests a change.

### 1. Load Zone Results

Read `{sidecarStatePath}` and `{deepTestingReportPath}`.

Extract from sidecar-state:
- `completedZones` with status flags and test counts
- Count per status: approved, skipped, spawn-failed
- Total zones vs processed
- Discovery integration results

Extract from report:
- Per-zone results already written during step-02
- Discovery findings summary from step-03

### 2. Compute Global Metrics

**Calculate:**
- **Total tests written:** sum across all approved zones (unit + integration + edge)
- **Tests by type:** total unit, total integration, total edge cases
- **Zone completion rate:** approved / total zones (%)
- **Discovery count:** bugs + untestable code + surprising behaviors + fixture gaps
- **Known issues:** count of tests marked as known_issue (existing bugs exposed)

**Update Global Metrics section in `{deepTestingReportPath}`:**

| MÃ©trique | Valeur |
|----------|--------|
| Zones traitÃ©es | {approved + skipped}/{total} |
| Zones approuvÃ©es | {approved} |
| Zones skippÃ©es | {skipped} |
| Tests Ã©crits (total) | {total_tests} |
| â€” Unit tests | {unit_count} |
| â€” Integration tests | {integration_count} |
| â€” Edge case tests | {edge_count} |
| Known issues exposÃ©s | {known_count} |
| DÃ©couvertes intÃ©grÃ©es | {discovery_count} |

### 3. Generate Executive Summary

Write the Executive Summary section in `{deepTestingReportPath}`:

"{N} zones de risque traitÃ©es par le Deep Tester.

**RÃ©sultats :**
- {approved} zones approuvÃ©es avec {total_tests} tests Ã©crits
- {skipped} zones skippÃ©es {brief reason if applicable}
- {known_count} bugs existants dÃ©couverts par les tests (marquÃ©s known_issue)

**Couverture par type :**
- **Unit :** {unit_count} tests â€” {qualitative: logique mÃ©tier, transformations, validateurs}
- **Integration :** {integration_count} tests â€” {qualitative: interactions composants, flux API}
- **Edge cases :** {edge_count} tests â€” {qualitative: valeurs limites, chemins d'erreur}

**DÃ©couvertes :**
{count} trouvailles intÃ©grÃ©es au risk map â€” {brief categorization}"

### 4. Assess Confidence

For each zone, determine confidence level based on:
- Test count and depth (unit + integration + edge = high, unit + integration = medium, unit only = low)
- Known issues (many known issues = lower confidence in code quality)
- Untestable code (untestable areas = gap in confidence)

**Write Confidence Assessment section in `{deepTestingReportPath}`:**

"**Ã‰valuation de la confiance :**

| Zone | Profondeur | Tests | Known Issues | Confiance |
|------|-----------|-------|--------------|-----------|
| {zone} | {depth} | {count} | {known} | {ğŸŸ¢ Haute / ğŸŸ¡ Moyenne / ğŸ”´ Basse} |

**Confiance globale : {ğŸŸ¢/ğŸŸ¡/ğŸ”´} â€” {one-line justification}**"

### 5. Document Remaining Gaps

**Identify areas NOT covered by deep testing:**
- Zones that were skipped or spawn-failed
- Code identified as untestable despite refactoring
- Areas where only partial depth was achieved (unit only, no integration)
- Known issues that remain unresolved

**Write Remaining Gaps section in `{deepTestingReportPath}`:**

"**Lacunes restantes :**
- {list of gaps with zone, reason, and recommended action}

**Zones non-testÃ©es :** {list of skipped zones with reason}"

### 6. Generate Recommendations

Read `{riskMapPath}`, `{safetyNetsReportPath}`, and `{refactoringReportPath}` for cross-phase context.

**Write Recommendations section in `{deepTestingReportPath}`:**

Recommendations should cover:

1. **Remaining coverage gaps** â€” what still needs attention (manual testing, targeted follow-up)
2. **Known issues** â€” which exposed bugs should be prioritized for fixing (based on risk score)
3. **Untestable code** â€” whether additional refactoring is warranted or risk is acceptable
4. **Test maintenance** â€” strategy for keeping the new test suite healthy over time
5. **Guard workflow** â€” mention the LCS Guard workflow is available for ongoing maintenance and regression monitoring

### 7. Finalize Report

Update `{deepTestingReportPath}` frontmatter:
- Append `step-04-report` to `stepsCompleted`
- Set `lastStep` to `step-04-report`
- Set `status` to `complete`
- Set `completedDate` to current date

### 8. Update Sidecar State

Update `{sidecarStatePath}`:
- Set deep-testing phase status to `complete`
- Set `consolidation.last_session` to current date
- Note: do NOT advance `consolidation.current_phase` â€” that's the lead agent's responsibility at workflow orchestration level

### 9. Present Final Summary

"**Rapport de deep testing finalisÃ©.**

**RÃ©sultats globaux :**
| MÃ©trique | Valeur |
|----------|--------|
| Zones traitÃ©es | {N}/{total} |
| Tests Ã©crits | {total_tests} |
| Known issues exposÃ©s | {known_count} |
| DÃ©couvertes intÃ©grÃ©es | {discovery_count} |
| Confiance globale | {ğŸŸ¢/ğŸŸ¡/ğŸ”´} |

**Rapport sauvegardÃ© :** `{deepTestingReportPath}`

---

**Le pipeline LCS (Phases 0 Ã  4) est maintenant complet.**

| Phase | Workflow | Statut |
|-------|----------|--------|
| Phase 0 | Pre-flight | âœ… ComplÃ©tÃ© |
| Phase 1 | Audit | âœ… ComplÃ©tÃ© |
| Phase 2 | Safety Nets | âœ… ComplÃ©tÃ© |
| Phase 2b | Dependency Update | âœ… ComplÃ©tÃ© |
| Phase 3 | Refactoring | âœ… ComplÃ©tÃ© |
| Phase 4 | Deep Testing | âœ… ComplÃ©tÃ© |

**Votre codebase legacy est dÃ©sormais consolidÃ©e** â€” auditÃ©e, protÃ©gÃ©e par des filets de sÃ©curitÃ©, refactorisÃ©e, et couverte par des tests approfondis.

**Pour la maintenance continue :** le workflow **Guard** est disponible pour le monitoring des rÃ©gressions et la protection continue de votre codebase.

**Merci pour votre collaboration tout au long de ce processus de consolidation !**"

---

## ğŸš¨ SYSTEM SUCCESS/FAILURE METRICS

### âœ… SUCCESS:

- All zone results loaded from sidecar-state and report
- Global metrics computed accurately from actual zone outcomes
- Executive summary synthesizes coverage achieved and discoveries
- Confidence assessment per zone with overall assessment
- Remaining gaps documented honestly
- Recommendations are actionable and cross-reference prior phases
- Report frontmatter updated with complete status
- Sidecar-state updated with phase completion
- LCS pipeline completion summary presented
- Guard workflow mentioned for ongoing maintenance
- Clear final summary presented to user

### âŒ SYSTEM FAILURE:

- Inaccurate metrics (not matching actual zone outcomes)
- Missing executive summary or confidence assessment
- Not documenting remaining gaps
- Generic recommendations not tied to actual results
- Not updating report frontmatter to complete
- Not updating sidecar-state
- Not presenting the LCS pipeline completion summary
- Writing tests or modifying code in this step

**Master Rule:** The report is the deliverable. It must accurately reflect what was tested, what was discovered, and what confidence level the codebase has reached. No fluff, no padding â€” honest synthesis. The LCS pipeline completion is a significant milestone â€” present it clearly.
